{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbab9cd9",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83a9d7",
   "metadata": {},
   "source": [
    "# The Evolution from LLMs to Autonomous Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5827e0",
   "metadata": {},
   "source": [
    "Language models have undergone a remarkable transformation over the past few decades, evolving from simple statistical approaches to the sophisticated Large Language Models (LLMs) we interact with today. This evolution represents not just technological advancement, but a fundamental shift in how we conceptualize machine intelligence and human-computer interaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d83832",
   "metadata": {},
   "source": [
    "**The Early Days: Statistical Language Modeling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156e5c2",
   "metadata": {},
   "source": [
    "The roots of modern language models can be traced back to statistical approaches developed in the late 20th century. These early models were primarily focused on predicting the probability of a sequence of words, using techniques like n-grams and hidden Markov models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8ca7b",
   "metadata": {},
   "source": [
    "In statistical language modeling, the probability of a word sequence $W = (w_1, w_2, ..., w_n)$ was calculated using the chain rule of probability:\n",
    "\n",
    "$P(W) = P(w_1, w_2, ..., w_n) = P(w_1) \\times P(w_2|w_1) \\times P(w_3|w_1,w_2) \\times ... \\times P(w_n|w_1,...,w_{n-1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eaa685",
   "metadata": {},
   "source": [
    "These models made a simplifying assumption known as the Markov assumption, where the probability of a word depended only on a fixed number of preceding words:\n",
    "\n",
    "$P(w_n|w_1,...,w_{n-1}) \\approx P(w_n|w_{n-k},...,w_{n-1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60682f",
   "metadata": {},
   "source": [
    "While innovative for their time, these models struggled with long-range dependencies and semantic understanding, often producing text that was grammatically plausible but semantically incoherent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a73d5",
   "metadata": {},
   "source": [
    "**Neural Language Models: The First Revolution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c37b71",
   "metadata": {},
   "source": [
    "The introduction of neural networks to language modeling in the early 2010s marked the first major revolution in the field. Models like Word2Vec (2013) and GloVe (2014) introduced the concept of word embeddings, which represented words as dense vectors in a continuous space where semantically similar words were positioned closer together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8b978",
   "metadata": {},
   "source": [
    "These embedding models captured semantic relationships in surprising ways. For example, the vector operation:\n",
    "\n",
    "$\\text{vector(\"king\")} - \\text{vector(\"man\")} + \\text{vector(\"woman\")} \\approx \\text{vector(\"queen\")}$\n",
    "\n",
    "This demonstrated that these models were learning meaningful semantic relationships from data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc144c3",
   "metadata": {},
   "source": [
    "The real breakthrough came with recurrent neural networks (RNNs), particularly Long Short-Term Memory (LSTM) networks, which could process sequences of varying lengths and capture longer-range dependencies. However, these models still faced limitations with very long sequences due to the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e322f17",
   "metadata": {},
   "source": [
    "**The Transformer Revolution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cd522",
   "metadata": {},
   "source": [
    "In 2017, the publication of \"Attention Is All You Need\" introduced the Transformer architecture, which would become the foundation for all modern LLMs. The key innovation was the self-attention mechanism, which allowed models to weigh the importance of different words in a sequence regardless of their distance from each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2dedb",
   "metadata": {},
   "source": [
    "The self-attention mechanism computes attention scores using queries (Q), keys (K), and values (V):\n",
    "\n",
    "$\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcc1ef",
   "metadata": {},
   "source": [
    "This breakthrough addressed the limitations of sequential processing in RNNs and enabled highly parallelizable training on massive datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91db5d0",
   "metadata": {},
   "source": [
    "üí° **Tip:** The Transformer architecture's ability to process tokens in parallel (rather than sequentially) was a key factor enabling the scaling of language models to billions of parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb74d4",
   "metadata": {},
   "source": [
    "**The Scaling Era: From BERT to GPT**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf4885",
   "metadata": {},
   "source": [
    "Following the Transformer architecture, two main approaches emerged:\n",
    "\n",
    "1. **Encoder-only models** like BERT (2018), which excel at understanding context and are primarily used for tasks like classification and named entity recognition.\n",
    "\n",
    "2. **Decoder-only models** like GPT (2018), which excel at text generation by predicting the next token in a sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21666371",
   "metadata": {},
   "source": [
    "The scaling hypothesis ‚Äì that model capabilities would emerge simply by increasing model size and training data ‚Äì proved remarkably accurate. As models scaled from millions to billions of parameters, they demonstrated increasingly sophisticated capabilities:\n",
    "\n",
    "- GPT-2 (1.5B parameters, 2019) showed surprising zero-shot capabilities\n",
    "- GPT-3 (175B parameters, 2020) demonstrated few-shot learning\n",
    "- GPT-4 (estimated trillions of parameters, 2023) exhibited reasoning abilities approaching human performance in many domains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a9f98",
   "metadata": {},
   "source": [
    "**Emergent Abilities and In-Context Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7d99e",
   "metadata": {},
   "source": [
    "Perhaps the most fascinating aspect of modern LLMs is their emergent abilities ‚Äì capabilities not explicitly trained for that appear once models reach a certain scale. These include:\n",
    "\n",
    "- In-context learning (learning from examples provided in the prompt)\n",
    "- Chain-of-thought reasoning\n",
    "- Self-correction\n",
    "- Instruction following\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9bb86b",
   "metadata": {},
   "source": [
    "These capabilities emerged not from architectural changes but primarily from scale and training methodology. For example, the technique of Reinforcement Learning from Human Feedback (RLHF) has been crucial in aligning these models with human preferences and instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627a1c4",
   "metadata": {},
   "source": [
    "```python\n",
    "# Simple example of in-context learning with a modern LLM\n",
    "prompt = \"\"\"\n",
    "Translate English to French:\n",
    "sea otter => loutre de mer\n",
    "peppermint => menthe poivr√©e\n",
    "plush girafe => girafe en peluche\n",
    "cheese =>\n",
    "\"\"\"\n",
    "\n",
    "# The model can learn the pattern from examples and complete the translation\n",
    "# without being explicitly fine-tuned for translation\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cd028",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While modern LLMs demonstrate remarkable capabilities, they fundamentally remain next-token predictors. They generate text by predicting the most likely next token given the previous context, without explicit reasoning or planning mechanisms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb669470",
   "metadata": {},
   "source": [
    "This fundamental limitation of traditional LLMs ‚Äì being reactive text generators rather than proactive reasoning agents ‚Äì sets the stage for the emergence of agentic AI systems, which we'll explore in the next section."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
