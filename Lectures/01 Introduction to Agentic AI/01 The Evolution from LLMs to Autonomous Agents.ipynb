{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbab9cd9",
   "metadata": {},
   "source": [
    "<img src=\"./images/banner.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8bb81",
   "metadata": {},
   "source": [
    "# The Evolution from LLMs to Autonomous Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5827e0",
   "metadata": {},
   "source": [
    "Language models have undergone a remarkable transformation over the past few decades, evolving from simple statistical approaches to the sophisticated Large Language Models (LLMs) we interact with today. This evolution represents not just technological advancement, but a fundamental shift in how we conceptualize machine intelligence and human-computer interaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447a7288",
   "metadata": {},
   "source": [
    "<img src=\"./images/working-of-agentic-ai.webp\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d83832",
   "metadata": {},
   "source": [
    "**The Early Days: Statistical Language Modeling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8156e5c2",
   "metadata": {},
   "source": [
    "The roots of modern language models can be traced back to statistical approaches developed in the late 20th century. These early models were primarily focused on predicting the probability of a sequence of words, using techniques like n-grams and hidden Markov models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8ca7b",
   "metadata": {},
   "source": [
    "In statistical language modeling, the probability of a word sequence $W = (w_1, w_2, ..., w_n)$ was calculated using the chain rule of probability:\n",
    "\n",
    "$P(W) = P(w_1, w_2, ..., w_n) = P(w_1) \\times P(w_2|w_1) \\times P(w_3|w_1,w_2) \\times ... \\times P(w_n|w_1,...,w_{n-1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eaa685",
   "metadata": {},
   "source": [
    "These models made a simplifying assumption known as the Markov assumption, where the probability of a word depended only on a fixed number of preceding words:\n",
    "\n",
    "$P(w_n|w_1,...,w_{n-1}) \\approx P(w_n|w_{n-k},...,w_{n-1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60682f",
   "metadata": {},
   "source": [
    "While innovative for their time, these models struggled with long-range dependencies and semantic understanding, often producing text that was grammatically plausible but semantically incoherent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a73d5",
   "metadata": {},
   "source": [
    "**Neural Language Models: The First Revolution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c37b71",
   "metadata": {},
   "source": [
    "The introduction of neural networks to language modeling in the early 2010s marked the first major revolution in the field. Models like Word2Vec (2013) and GloVe (2014) introduced the concept of word embeddings, which represented words as dense vectors in a continuous space where semantically similar words were positioned closer together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e8b978",
   "metadata": {},
   "source": [
    "These embedding models captured semantic relationships in surprising ways. For example, the vector operation:\n",
    "\n",
    "$\\text{vector(\"king\")} - \\text{vector(\"man\")} + \\text{vector(\"woman\")} \\approx \\text{vector(\"queen\")}$\n",
    "\n",
    "This demonstrated that these models were learning meaningful semantic relationships from data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5b1f5f",
   "metadata": {},
   "source": [
    "<img src=\"./images/word-embedding.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc144c3",
   "metadata": {},
   "source": [
    "The real breakthrough came with recurrent neural networks (RNNs), particularly Long Short-Term Memory (LSTM) networks, which could process sequences of varying lengths and capture longer-range dependencies. However, these models still faced limitations with very long sequences due to the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e322f17",
   "metadata": {},
   "source": [
    "**The Transformer Revolution**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2cd522",
   "metadata": {},
   "source": [
    "In 2017, the publication of \"Attention Is All You Need\" introduced the Transformer architecture, which would become the foundation for all modern LLMs. The key innovation was the self-attention mechanism, which allowed models to weigh the importance of different words in a sequence regardless of their distance from each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca2dedb",
   "metadata": {},
   "source": [
    "The self-attention mechanism computes attention scores using queries (Q), keys (K), and values (V):\n",
    "\n",
    "$\\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dcc1ef",
   "metadata": {},
   "source": [
    "This breakthrough addressed the limitations of sequential processing in RNNs and enabled highly parallelizable training on massive datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91db5d0",
   "metadata": {},
   "source": [
    "üí° **Tip:** The Transformer architecture's ability to process tokens in parallel (rather than sequentially) was a key factor enabling the scaling of language models to billions of parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb74d4",
   "metadata": {},
   "source": [
    "**The Scaling Era: From BERT to GPT**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf4885",
   "metadata": {},
   "source": [
    "Following the Transformer architecture, two main approaches emerged:\n",
    "\n",
    "1. **Encoder-only models** like BERT (2018), which excel at understanding context and are primarily used for tasks like classification and named entity recognition.\n",
    "\n",
    "2. **Decoder-only models** like GPT (2018), which excel at text generation by predicting the next token in a sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7112335",
   "metadata": {},
   "source": [
    "<img src=\"./images/encoder-decoder.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21666371",
   "metadata": {},
   "source": [
    "The scaling hypothesis ‚Äì that model capabilities would emerge simply by increasing model size and training data ‚Äì proved remarkably accurate. As models scaled from millions to billions of parameters, they demonstrated increasingly sophisticated capabilities:\n",
    "\n",
    "- GPT-2 (1.5B parameters, 2019) showed surprising zero-shot capabilities\n",
    "- GPT-3 (175B parameters, 2020) demonstrated few-shot learning\n",
    "- GPT-4 (estimated trillions of parameters, 2023) exhibited reasoning abilities approaching human performance in many domains\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a9f98",
   "metadata": {},
   "source": [
    "**Emergent Abilities and In-Context Learning**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7d99e",
   "metadata": {},
   "source": [
    "Perhaps the most fascinating aspect of modern LLMs is their emergent abilities ‚Äì capabilities not explicitly trained for that appear once models reach a certain scale. These include:\n",
    "\n",
    "- In-context learning (learning from examples provided in the prompt)\n",
    "- Chain-of-thought reasoning\n",
    "- Self-correction\n",
    "- Instruction following\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9bb86b",
   "metadata": {},
   "source": [
    "These capabilities emerged not from architectural changes but primarily from scale and training methodology. For example, the technique of Reinforcement Learning from Human Feedback (RLHF) has been crucial in aligning these models with human preferences and instructions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9627a1c4",
   "metadata": {},
   "source": [
    "```python\n",
    "# Simple example of in-context learning with a modern LLM\n",
    "prompt = \"\"\"\n",
    "Translate English to French:\n",
    "sea otter => loutre de mer\n",
    "peppermint => menthe poivr√©e\n",
    "plush girafe => girafe en peluche\n",
    "cheese =>\n",
    "\"\"\"\n",
    "\n",
    "# The model can learn the pattern from examples and complete the translation\n",
    "# without being explicitly fine-tuned for translation\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690cd028",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** While modern LLMs demonstrate remarkable capabilities, they fundamentally remain next-token predictors. They generate text by predicting the most likely next token given the previous context, without explicit reasoning or planning mechanisms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb669470",
   "metadata": {},
   "source": [
    "This fundamental limitation of traditional LLMs ‚Äì being reactive text generators rather than proactive reasoning agents ‚Äì sets the stage for the emergence of agentic AI systems, which we'll explore in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34050f87",
   "metadata": {},
   "source": [
    "<img src=\"./images/basic-llm.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e3cb7",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Understanding the Limitations of Traditional LLMs](#toc1_)    \n",
    "  - [The Reactive Paradigm: Prompt-Response Limitations](#toc1_1_)    \n",
    "  - [The Context Window Constraint](#toc1_2_)    \n",
    "  - [The Hallucination Problem](#toc1_3_)    \n",
    "  - [The Tool Use Barrier](#toc1_4_)    \n",
    "  - [The Planning and Persistence Gap](#toc1_5_)    \n",
    "- [The Emergence of Agentic AI Systems](#toc2_)    \n",
    "  - [Defining AI Agency: From Reactive to Proactive](#toc2_1_)    \n",
    "  - [The Key Architectural Innovations](#toc2_2_)    \n",
    "    - [The ReAct Framework (Reasoning + Acting)](#toc2_2_1_)    \n",
    "    - [Tool Use and Function Calling](#toc2_2_2_)    \n",
    "    - [Memory and State Management Systems](#toc2_2_3_)    \n",
    "  - [From AutoGPT to Modern Agent Frameworks](#toc2_3_)    \n",
    "    - [Early Experiments: AutoGPT and BabyAGI](#toc2_3_1_)    \n",
    "    - [The Emergence of Agent Frameworks](#toc2_3_2_)    \n",
    "  - [The OODA Loop for AI Agents](#toc2_4_)    \n",
    "  - [Real-World Applications Driving Adoption](#toc2_5_)    \n",
    "- [Conclusion: Bridging the Gap to Agentic AI](#toc3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425cc3d",
   "metadata": {},
   "source": [
    "## <a id='toc1_'></a>[Understanding the Limitations of Traditional LLMs](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbace56",
   "metadata": {},
   "source": [
    "While Large Language Models have demonstrated remarkable capabilities in generating human-like text, they face fundamental limitations that restrict their ability to function as truly intelligent agents. These limitations stem from their underlying architecture, training methodology, and operational design. Understanding these constraints is crucial for appreciating why the evolution toward agentic systems represents such a significant paradigm shift.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f7139",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_'></a>[The Reactive Paradigm: Prompt-Response Limitations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5640f030",
   "metadata": {},
   "source": [
    "Traditional LLMs operate within what we might call a \"reactive paradigm.\" They are designed to generate responses to prompts, functioning essentially as sophisticated autocomplete systems. This fundamental design creates several important limitations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40873ae3",
   "metadata": {},
   "source": [
    "The interaction pattern follows a rigid structure: the user provides a prompt, the model generates a response, and the conversation continues in discrete turns. This back-and-forth pattern lacks the continuity and autonomy needed for many real-world tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e209337d",
   "metadata": {},
   "source": [
    "```\n",
    "User: \"What's the weather like today?\"\n",
    "LLM: \"I don't have access to real-time weather information. To get the current weather, you would need to check a weather service or app.\"\n",
    "User: \"Can you help me find a weather service?\"\n",
    "LLM: \"Sure, you can use websites like Weather.com, AccuWeather, or the National Weather Service...\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da59159",
   "metadata": {},
   "source": [
    "In this example, the LLM cannot take the initiative to check the weather itself, even though this would be the most helpful response. It can only react to the specific prompt provided, creating a disjointed user experience that requires multiple interactions to accomplish simple tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434fbe07",
   "metadata": {},
   "source": [
    "üí° **Tip:** When working with traditional LLMs, breaking complex tasks into smaller, explicit steps often yields better results than expecting the model to handle multi-step processes autonomously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0620ea5",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_'></a>[The Context Window Constraint](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b427c5",
   "metadata": {},
   "source": [
    "LLMs process information within a fixed \"context window\" ‚Äì the maximum number of tokens they can consider at once. This creates several significant limitations:\n",
    "\n",
    "1. **Limited memory**: The model can only \"remember\" information provided within the current context window. Once information falls outside this window, it's effectively forgotten.\n",
    "\n",
    "2. **No persistent state**: Traditional LLMs have no built-in mechanism to maintain state across separate interactions. Each new prompt essentially restarts the system.\n",
    "\n",
    "3. **Inability to handle long-running tasks**: Tasks that require processing information beyond the context window or maintaining awareness over extended periods become problematic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fbd62",
   "metadata": {},
   "source": [
    "<img src=\"./images/context-window.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8dd9db",
   "metadata": {},
   "source": [
    "The context window limitation becomes particularly apparent when dealing with complex documents or conversations that span multiple interactions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df586ef4",
   "metadata": {},
   "source": [
    "```python\n",
    "# Example demonstrating context window limitations\n",
    "conversation = [\n",
    "    \"User: Can you analyze this 300-page financial report?\",\n",
    "    \"LLM: I can help with that, but I can only process portions of the document at a time due to my context window limitations.\",\n",
    "    \"User: Ok, let's start with the executive summary.\",\n",
    "    # ... many interactions later\n",
    "    \"User: How does this compare to the projection on page 27?\",\n",
    "    \"LLM: I don't currently have access to page 27 as it's no longer in my context window. Could you share that section again?\"\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ba286",
   "metadata": {},
   "source": [
    "As models scale, context windows have expanded (from 2,048 tokens in early GPT models to over 100,000 in some recent models), but the fundamental limitation remains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d20b0",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_'></a>[The Hallucination Problem](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed29e2",
   "metadata": {},
   "source": [
    "One of the most significant limitations of traditional LLMs is their tendency to generate content that sounds plausible but is factually incorrect ‚Äì a phenomenon commonly referred to as \"hallucination.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3333099",
   "metadata": {},
   "source": [
    "Hallucinations occur for several reasons:\n",
    "\n",
    "1. **Training on internet-scale data**: LLMs are trained on vast datasets that include inaccurate information, leading them to sometimes reproduce these inaccuracies.\n",
    "\n",
    "2. **Probabilistic next-token prediction**: The fundamental mechanism of predicting the next most likely token can lead to generating plausible-sounding but incorrect information when the model is uncertain.\n",
    "\n",
    "3. **No built-in verification mechanisms**: Traditional LLMs lack the ability to verify their outputs against reliable knowledge sources or recognize when they're operating outside their knowledge boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f11ee8",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** Hallucinations represent a critical limitation for applications requiring factual accuracy, such as medical advice, legal analysis, or educational content. This is why retrieval augmentation has become essential for production LLM applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea023e",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_'></a>[The Tool Use Barrier](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b900266",
   "metadata": {},
   "source": [
    "Perhaps the most significant limitation preventing traditional LLMs from functioning as agents is their inability to interact with external tools, systems, and environments without specialized frameworks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae3107",
   "metadata": {},
   "source": [
    "By default, LLMs can only manipulate text ‚Äì they cannot:\n",
    "- Access the internet to retrieve current information\n",
    "- Use specialized tools (calculators, databases, APIs)\n",
    "- Interact with operating systems or applications\n",
    "- Perceive or act upon the physical world\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b850b739",
   "metadata": {},
   "source": [
    "This creates a fundamental barrier between language models and the world they're meant to help users navigate. Consider this simple example:\n",
    "\n",
    "```\n",
    "User: \"What's the current price of Apple stock?\"\n",
    "Basic LLM: \"I don't have access to real-time stock information. The last data I have for Apple stock is from my training cutoff date. For current prices, you would need to check a financial website or stock market application.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5f4ab",
   "metadata": {},
   "source": [
    "The LLM recognizes what information would be helpful but lacks the capability to retrieve it independently. This represents a fundamental limitation of the paradigm, not just a technical implementation detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441937a9",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_'></a>[The Planning and Persistence Gap](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99ca61d",
   "metadata": {},
   "source": [
    "Traditional LLMs lack two critical capabilities required for agency:\n",
    "\n",
    "1. **Planning capability**: The ability to break down complex goals into manageable steps, reason about dependencies, and create execution strategies.\n",
    "\n",
    "2. **Persistence**: The ability to maintain state, monitor progress, and adapt plans over extended periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb9b99",
   "metadata": {},
   "source": [
    "Without these capabilities, LLMs cannot effectively:\n",
    "- Pursue goals independently\n",
    "- Adapt to changing circumstances\n",
    "- Learn from failures and adjust strategies\n",
    "- Maintain awareness of progress over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b128c49f",
   "metadata": {},
   "source": [
    "This planning and persistence gap becomes evident when asking an LLM to help with complex, multi-step tasks:\n",
    "\n",
    "```\n",
    "User: \"Help me plan a trip to Japan next month.\"\n",
    "LLM: *Provides general advice about planning a trip to Japan*\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4681b4",
   "metadata": {},
   "source": [
    "While the response might be informative, a traditional LLM cannot:\n",
    "- Remember this goal across conversations\n",
    "- Proactively suggest next steps in the planning process\n",
    "- Adapt recommendations based on booking outcomes\n",
    "- Track progress toward the overall goal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900414f0",
   "metadata": {},
   "source": [
    "These limitations collectively create a ceiling on what traditional LLMs can accomplish, regardless of scale or training. They represent fundamental constraints of the reactive, prompt-response paradigm ‚Äì constraints that the evolution toward agentic systems specifically aims to overcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c519c6",
   "metadata": {},
   "source": [
    "## <a id='toc2_'></a>[The Emergence of Agentic AI Systems](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7bad3c",
   "metadata": {},
   "source": [
    "The transition from traditional Large Language Models to agentic AI systems represents a fundamental paradigm shift in artificial intelligence. This evolution addresses many of the core limitations we discussed previously, enabling a new class of AI systems that can operate with greater autonomy, persistence, and effectiveness. In this section, we'll explore how agentic systems emerged, their defining characteristics, and the frameworks that enable their capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27db388",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_'></a>[Defining AI Agency: From Reactive to Proactive](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9b91e",
   "metadata": {},
   "source": [
    "At its core, an AI agent is a system that can perceive its environment, make decisions, and take actions to achieve specific goals. The key distinction between traditional LLMs and agentic systems lies in their relationship to action and purpose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3affe",
   "metadata": {},
   "source": [
    "Traditional LLMs are fundamentally reactive text generators, while agentic systems are proactive goal pursuers. This shift can be characterized along several dimensions:\n",
    "\n",
    "| Dimension | Traditional LLMs | Agentic Systems |\n",
    "|-----------|------------------|-----------------|\n",
    "| Interaction mode | Reactive (prompt-response) | Proactive (goal-oriented) |\n",
    "| Temporal scope | Immediate (single turn) | Extended (persistent) |\n",
    "| Action capability | Text generation only | Tool use and environment interaction |\n",
    "| Decision making | Implicit in text generation | Explicit planning and reasoning |\n",
    "| State management | Stateless or limited by context window | Persistent memory and state tracking |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2453fa1e",
   "metadata": {},
   "source": [
    "The concept of agency in AI isn't entirely new‚Äîit has roots in classical AI research dating back decades. However, what makes modern agentic systems revolutionary is their combination of LLM capabilities with structured frameworks for planning, reasoning, and action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e399b6",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_'></a>[The Key Architectural Innovations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c617e",
   "metadata": {},
   "source": [
    "The emergence of agentic AI systems has been driven by several key architectural innovations that build upon the foundation of LLMs:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845c664",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_1_'></a>[The ReAct Framework (Reasoning + Acting)](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a47b4",
   "metadata": {},
   "source": [
    "One of the earliest and most influential frameworks for LLM agency is ReAct (Reasoning + Acting), which combines chain-of-thought reasoning with the ability to take actions. The ReAct pattern typically follows this structure:\n",
    "\n",
    "```\n",
    "Thought: I need to determine X. I should use tool Y to find the information.\n",
    "Action: [Use tool Y with specific parameters]\n",
    "Observation: [Result from tool Y]\n",
    "Thought: Based on this result, I can conclude Z. Now I need to...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebd6f2",
   "metadata": {},
   "source": [
    "This structured approach allows LLMs to break down complex tasks, reason about intermediate steps, take appropriate actions, and incorporate feedback‚Äîall within a single framework.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1dfdc",
   "metadata": {},
   "source": [
    "```python\n",
    "# Simplified ReAct pattern implementation\n",
    "def react_agent(query, tools):\n",
    "    context = f\"Query: {query}\\n\"\n",
    "    \n",
    "    while not is_complete(context):\n",
    "        # Generate the next thought, action, or response\n",
    "        next_step = llm_generate(context + \"Thought: \")\n",
    "        context += next_step\n",
    "        \n",
    "        # If the model decides to use a tool\n",
    "        if \"Action:\" in next_step:\n",
    "            tool_call = parse_tool_call(next_step)\n",
    "            tool_result = execute_tool(tools, tool_call)\n",
    "            context += f\"Observation: {tool_result}\\n\"\n",
    "    \n",
    "    return extract_final_response(context)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c64699",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_2_'></a>[Tool Use and Function Calling](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ecff4",
   "metadata": {},
   "source": [
    "A critical capability enabling agency is the ability for LLMs to interact with external tools and APIs. This has been implemented through various approaches:\n",
    "\n",
    "- **Structured output parsing**: Early approaches used careful prompting to have LLMs generate structured outputs (like JSON) that could be parsed into function calls.\n",
    "\n",
    "- **Function calling APIs**: Modern LLM providers now offer native function calling capabilities, allowing models to explicitly select functions and provide parameters in a structured format.\n",
    "\n",
    "- **Tool libraries**: Ecosystems of pre-built tools that LLMs can leverage for specific capabilities like web search, calculation, code execution, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90646309",
   "metadata": {},
   "source": [
    "Tool use enables LLMs to overcome one of their fundamental limitations‚Äîthe inability to interact with the world beyond text generation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f3674",
   "metadata": {},
   "source": [
    "#### <a id='toc2_2_3_'></a>[Memory and State Management Systems](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec196b",
   "metadata": {},
   "source": [
    "To address the context window limitations and enable persistence, agentic systems implement various forms of memory:\n",
    "\n",
    "- **Short-term memory**: Maintaining recent conversation history\n",
    "- **Long-term memory**: Storing important information in vector databases for retrieval\n",
    "- **Working memory**: Tracking current goals, plans, and progress\n",
    "- **Episodic memory**: Recording sequences of interactions for future reference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79474b15",
   "metadata": {},
   "source": [
    "<img src=\"./images/memory-types.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04940069",
   "metadata": {},
   "source": [
    "These memory systems allow agents to maintain coherence across interactions and pursue goals over extended periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b6e10f",
   "metadata": {},
   "source": [
    "üí° **Tip:** Effective memory management is often the key differentiator between basic LLM applications and sophisticated agents that can maintain context and pursue complex goals over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0be0b",
   "metadata": {},
   "source": [
    "### <a id='toc2_3_'></a>[From AutoGPT to Modern Agent Frameworks](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46361344",
   "metadata": {},
   "source": [
    "The emergence of agentic AI systems can be traced through several influential projects and frameworks:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634d349",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_1_'></a>[Early Experiments: AutoGPT and BabyAGI](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adae958",
   "metadata": {},
   "source": [
    "In early 2023, projects like AutoGPT and BabyAGI demonstrated the potential of autonomous LLM-based agents. These systems combined several key components:\n",
    "\n",
    "1. Goal specification by users\n",
    "2. Autonomous task planning and decomposition\n",
    "3. Tool use for information gathering and task execution\n",
    "4. Self-reflection and plan adjustment\n",
    "5. Memory systems for tracking progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d562c9",
   "metadata": {},
   "source": [
    "While experimental in nature, these projects sparked tremendous interest by demonstrating that LLMs could function as autonomous agents with minimal additional architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1070872e",
   "metadata": {},
   "source": [
    "#### <a id='toc2_3_2_'></a>[The Emergence of Agent Frameworks](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c6e7ca",
   "metadata": {},
   "source": [
    "Following these early experiments, more sophisticated agent frameworks emerged, including:\n",
    "\n",
    "- **LangChain Agents**: Providing structured approaches for building agents with different planning strategies and tool integration\n",
    "- **CrewAI**: Enabling teams of specialized agents to collaborate on complex tasks\n",
    "- **AutoGen**: Microsoft's framework for building autonomous agents with different capabilities\n",
    "- **LlamaIndex Agent Framework**: Offering advanced RAG capabilities integrated with agency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec80afb",
   "metadata": {},
   "source": [
    "These frameworks standardized key patterns and provided reusable components for building agentic systems, making them more accessible to developers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1bc938",
   "metadata": {},
   "source": [
    "### <a id='toc2_5_'></a>[Real-World Applications Driving Adoption](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a314b6",
   "metadata": {},
   "source": [
    "The emergence of agentic AI systems has been accelerated by compelling use cases that clearly demonstrate their advantages over traditional LLM applications:\n",
    "\n",
    "- **Research assistants** that can autonomously search for information, synthesize findings, and generate reports\n",
    "- **Coding agents** that can understand requirements, write code, test it, and debug issues\n",
    "- **Data analysis agents** that can clean data, perform analyses, and visualize results\n",
    "- **Customer service agents** that can handle complex issues requiring multiple steps and tool use\n",
    "- **Personal assistants** that can manage calendars, book appointments, and coordinate across services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa589dc3",
   "metadata": {},
   "source": [
    "These applications highlight how agency addresses core limitations of traditional LLMs and enables entirely new categories of AI systems that can operate with greater autonomy and effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca400e4c",
   "metadata": {},
   "source": [
    "The emergence of agentic AI represents not just a technical evolution but a fundamental shift in how we conceptualize AI systems‚Äîfrom tools we directly manipulate to assistants that can pursue goals on our behalf with increasing independence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8eb0af",
   "metadata": {},
   "source": [
    "## <a id='toc3_'></a>[Conclusion: Bridging the Gap to Agentic AI](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfede050",
   "metadata": {},
   "source": [
    "As we've explored throughout this lecture, Large Language Models represent a remarkable achievement in artificial intelligence, capable of generating human-like text, understanding complex instructions, and demonstrating emergent capabilities that weren't explicitly programmed. However, their fundamental limitations ‚Äì operating in a reactive paradigm, constrained by context windows, prone to hallucinations, unable to use tools independently, and lacking planning capabilities ‚Äì create a clear boundary between these systems and truly autonomous agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c6da8",
   "metadata": {},
   "source": [
    "This gap between traditional LLMs and agentic AI systems isn't merely a matter of incremental improvement but represents a paradigm shift in how we conceptualize AI systems. While LLMs excel at understanding and generating language, they remain fundamentally passive systems waiting for human prompts. Agentic systems, by contrast, can take initiative, maintain persistent goals, interact with their environment, and operate autonomously over extended periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cff2b7",
   "metadata": {},
   "source": [
    "The evolution from LLMs to autonomous agents involves addressing each of the limitations we've discussed:\n",
    "\n",
    "- Moving beyond the reactive prompt-response paradigm to proactive goal-oriented behavior\n",
    "- Implementing persistent memory systems that transcend context window limitations\n",
    "- Incorporating verification mechanisms and knowledge retrieval to mitigate hallucinations\n",
    "- Enabling seamless tool use and environmental interaction\n",
    "- Developing sophisticated planning and monitoring capabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd2cdd",
   "metadata": {},
   "source": [
    "üí° **Tip:** Think of the difference between LLMs and agents as similar to the difference between a reference librarian who can only answer questions about books and an executive assistant who can proactively manage your calendar, make reservations, and accomplish tasks on your behalf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f331e9",
   "metadata": {},
   "source": [
    "In the upcoming sections, we'll explore how frameworks like LlamaIndex help bridge this gap, transforming powerful but passive language models into autonomous agents capable of pursuing goals, using tools, and maintaining awareness over time. We'll examine the architectural components, design patterns, and technical approaches that enable this transformation, along with the practical applications and ethical considerations that emerge as AI systems become increasingly autonomous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1556723",
   "metadata": {},
   "source": [
    "The journey from statistical language models to modern LLMs has already transformed how we interact with technology. The evolution from LLMs to agentic AI promises an equally profound shift ‚Äì one that may fundamentally redefine the relationship between humans and artificial intelligence systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba809c35",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Important Note:** As we move toward more autonomous AI systems, understanding both the capabilities and limitations of these technologies becomes increasingly important. The goal isn't necessarily to create fully autonomous systems in all contexts, but rather to develop appropriate levels of agency for specific applications while maintaining human oversight and control.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba9559e",
   "metadata": {},
   "source": [
    "In our next lecture, we'll dive deeper into the core components that transform LLMs into agents, examining the architectural elements that enable perception, reasoning, planning, and action in agentic AI systems."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
